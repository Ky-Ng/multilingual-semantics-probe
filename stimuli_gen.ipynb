{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b6f226",
   "metadata": {},
   "source": [
    "# Multilingual Semantics Probe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ea80eb",
   "metadata": {},
   "source": [
    "## Step 1: Corpus Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9961ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c6656ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "STIMULI_DIR = \"./stimuli\"\n",
    "\n",
    "if not os.path.exists(STIMULI_DIR):\n",
    "    os.mkdir(STIMULI_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5aba402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- English lexicon ---\n",
    "EN_SUBJECTS = [\n",
    "    \"shark\",\n",
    "    \"robot\",\n",
    "    \"chef\",\n",
    "    \"dog\",\n",
    "]\n",
    "\n",
    "EN_OBJECTS = [\n",
    "    \"pirate\",\n",
    "    \"student\",\n",
    "    \"doctor\",\n",
    "    \"tourist\",\n",
    "]\n",
    "\n",
    "# Use correct simple past forms\n",
    "EN_VERBS_PAST = [\n",
    "    \"ate\",\n",
    "    \"helped\",\n",
    "    \"pushed\",\n",
    "    \"chased\",\n",
    "]\n",
    "\n",
    "# --- Mandarin lexicon ---\n",
    "# Bare nouns only (no quantifiers inside)\n",
    "ZH_SUBJECTS = [\n",
    "    \"鲨鱼\",\n",
    "    \"机器人\",\n",
    "    \"厨师\",\n",
    "    \"狗\",\n",
    "]\n",
    "\n",
    "ZH_OBJECTS = [\n",
    "    \"海盗\",\n",
    "    \"学生\",\n",
    "    \"医生\",\n",
    "    \"游客\",\n",
    "]\n",
    "\n",
    "# Verb stems compatible with 了\n",
    "ZH_VERBS = [\n",
    "    \"吃\",\n",
    "    \"帮助\",\n",
    "    \"推\",\n",
    "    \"追\",\n",
    "]\n",
    "\n",
    "# Optional classifier map (defaults to 个)\n",
    "ZH_CLASSIFIER: Dict[str, str] = {\n",
    "    \"鲨鱼\": \"只\",\n",
    "    \"狗\": \"只\",\n",
    "    \"机器人\": \"个\",\n",
    "    \"厨师\": \"个\",\n",
    "    \"海盗\": \"个\",\n",
    "    \"学生\": \"个\",\n",
    "    \"医生\": \"个\",\n",
    "    \"游客\": \"个\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a60565",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_TEMPLATES = [\n",
    "    # Classic ambiguous English form\n",
    "    \"A {subj} {verb_past} every {obj}.\",\n",
    "]\n",
    "\n",
    "ZH_TEMPLATES = [\n",
    "    # Canonical Mandarin surface-scope reading\n",
    "    \"有一{cl}{subj}{verb}了每个{obj}。\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2202da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Stimulus:\n",
    "    language: str\n",
    "    template_id: str\n",
    "    subj: str\n",
    "    obj: str\n",
    "    verb: str\n",
    "    sentence: str\n",
    "\n",
    "\n",
    "def get_classifier(noun: str, cl_map: Dict[str, str]) -> str:\n",
    "    return cl_map.get(noun, \"个\")\n",
    "\n",
    "\n",
    "def generate_english(\n",
    "    subjects: List[str],\n",
    "    objects: List[str],\n",
    "    verbs_past: List[str],\n",
    ") -> List[Stimulus]:\n",
    "    out: List[Stimulus] = []\n",
    "    for tid, tmpl in enumerate(EN_TEMPLATES):\n",
    "        for subj, obj, verb in itertools.product(subjects, objects, verbs_past):\n",
    "            out.append(\n",
    "                Stimulus(\n",
    "                    language=\"en\",\n",
    "                    template_id=f\"en_{tid}\",\n",
    "                    subj=subj,\n",
    "                    obj=obj,\n",
    "                    verb=verb,\n",
    "                    sentence=tmpl.format(\n",
    "                        subj=subj,\n",
    "                        obj=obj,\n",
    "                        verb_past=verb,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "    return out\n",
    "\n",
    "\n",
    "def generate_mandarin(\n",
    "    subjects: List[str],\n",
    "    objects: List[str],\n",
    "    verbs: List[str],\n",
    "    cl_map: Dict[str, str],\n",
    ") -> List[Stimulus]:\n",
    "    out: List[Stimulus] = []\n",
    "    for tid, tmpl in enumerate(ZH_TEMPLATES):\n",
    "        for subj, obj, verb in itertools.product(subjects, objects, verbs):\n",
    "            cl = get_classifier(subj, cl_map)\n",
    "            out.append(\n",
    "                Stimulus(\n",
    "                    language=\"zh\",\n",
    "                    template_id=f\"zh_{tid}\",\n",
    "                    subj=subj,\n",
    "                    obj=obj,\n",
    "                    verb=verb,\n",
    "                    sentence=tmpl.format(\n",
    "                        cl=cl,\n",
    "                        subj=subj,\n",
    "                        obj=obj,\n",
    "                        verb=verb,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e34c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = []\n",
    "stimuli += generate_english(EN_SUBJECTS, EN_OBJECTS, EN_VERBS_PAST)\n",
    "stimuli += generate_mandarin(ZH_SUBJECTS, ZH_OBJECTS, ZH_VERBS, ZH_CLASSIFIER)\n",
    "\n",
    "continuation_df = pd.DataFrame([s.__dict__ for s in stimuli])\n",
    "\n",
    "# Stable IDs for downstream scoring\n",
    "continuation_df.insert(\n",
    "    0,\n",
    "    \"stimulus_id\",\n",
    "    [\n",
    "        f\"{row.language}-{row.template_id}-{row.Index:06d}\"\n",
    "        for row in continuation_df.itertuples()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186f7040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stimuli: 128\n",
      "language\n",
      "en    64\n",
      "zh    64\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stimulus_id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>en-en_0-000045</td>\n",
       "      <td>A chef helped every tourist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>en-en_0-000029</td>\n",
       "      <td>A robot helped every tourist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>en-en_0-000043</td>\n",
       "      <td>A chef chased every doctor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>en-en_0-000061</td>\n",
       "      <td>A dog helped every tourist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>en-en_0-000034</td>\n",
       "      <td>A chef pushed every pirate.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stimulus_id                       sentence\n",
       "45  en-en_0-000045   A chef helped every tourist.\n",
       "29  en-en_0-000029  A robot helped every tourist.\n",
       "43  en-en_0-000043    A chef chased every doctor.\n",
       "61  en-en_0-000061    A dog helped every tourist.\n",
       "34  en-en_0-000034    A chef pushed every pirate."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stimulus_id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>zh-zh_0-000109</td>\n",
       "      <td>有一个厨师帮助了每个游客。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>zh-zh_0-000093</td>\n",
       "      <td>有一个机器人帮助了每个游客。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>zh-zh_0-000107</td>\n",
       "      <td>有一个厨师追了每个医生。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>zh-zh_0-000125</td>\n",
       "      <td>有一只狗帮助了每个游客。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>zh-zh_0-000098</td>\n",
       "      <td>有一个厨师推了每个海盗。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stimulus_id        sentence\n",
       "109  zh-zh_0-000109   有一个厨师帮助了每个游客。\n",
       "93   zh-zh_0-000093  有一个机器人帮助了每个游客。\n",
       "107  zh-zh_0-000107    有一个厨师追了每个医生。\n",
       "125  zh-zh_0-000125    有一只狗帮助了每个游客。\n",
       "98   zh-zh_0-000098    有一个厨师推了每个海盗。"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Total stimuli:\", len(continuation_df))\n",
    "print(continuation_df[\"language\"].value_counts())\n",
    "\n",
    "display(\n",
    "    continuation_df[continuation_df[\"language\"] == \"en\"][[\"stimulus_id\", \"sentence\"]].sample(\n",
    "        min(5, (continuation_df[\"language\"] == \"en\").sum()),\n",
    "        random_state=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "display(\n",
    "    continuation_df[continuation_df[\"language\"] == \"zh\"][[\"stimulus_id\", \"sentence\"]].sample(\n",
    "        min(5, (continuation_df[\"language\"] == \"zh\").sum()),\n",
    "        random_state=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "891de94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote stimuli.csv and stimuli.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Serialize\n",
    "continuation_df.to_csv(os.path.join(STIMULI_DIR,\"stimuli.csv\"), index=False)\n",
    "\n",
    "with open(os.path.join(STIMULI_DIR, \"stimuli.jsonl\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in continuation_df.to_dict(orient=\"records\"):\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Wrote stimuli.csv and stimuli.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79665af",
   "metadata": {},
   "source": [
    "### Add Natural Language Continuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9bc3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_CONTINUATIONS = {\n",
    "    \"surface\": \" There was only one {subj}.\",\n",
    "    \"inverse\": \" There were many {subj}.\",\n",
    "}\n",
    "\n",
    "# Mandarin: keep equally short.\n",
    "# Note: plural is usually implicit; \"很多\" is a decent lexical cue.\n",
    "ZH_CONTINUATIONS = {\n",
    "    \"surface\": \" 只有一{cl}{subj}。\",\n",
    "    \"inverse\": \" 有很多{cl}{subj}。\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b3708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_continuations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for r in df.itertuples(index=False):\n",
    "        base = r._asdict()\n",
    "\n",
    "        if base[\"language\"] == \"en\":\n",
    "            # naive pluralization: add \"s\"\n",
    "            # If you care about irregular plurals later, add a map.\n",
    "            subj_plural = base[\"subj\"] + \"s\"\n",
    "            cont_map = {\n",
    "                \"surface\": EN_CONTINUATIONS[\"surface\"].format(subj=base[\"subj\"]),\n",
    "                \"inverse\": EN_CONTINUATIONS[\"inverse\"].format(subj=subj_plural),\n",
    "            }\n",
    "\n",
    "        elif base[\"language\"] == \"zh\":\n",
    "            cl = ZH_CLASSIFIER.get(base[\"subj\"], \"个\")\n",
    "            cont_map = {\n",
    "                \"surface\": ZH_CONTINUATIONS[\"surface\"].format(cl=cl, subj=base[\"subj\"]),\n",
    "                \"inverse\": ZH_CONTINUATIONS[\"inverse\"].format(cl=cl, subj=base[\"subj\"]),\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown language: {base['language']}\")\n",
    "\n",
    "        for cont_type, cont_text in cont_map.items():\n",
    "            ex = dict(base)\n",
    "            ex[\"continuation_type\"] = cont_type            # \"surface\" or \"inverse\"\n",
    "            ex[\"continuation_text\"] = cont_text            # the thing you'll score\n",
    "            ex[\"full_text\"] = base[\"sentence\"] + cont_text # convenient for debugging\n",
    "            rows.append(ex)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217600e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont = add_continuations(continuation_df)\n",
    "\n",
    "if \"concept_id\" not in df_cont.columns:\n",
    "    concept_series = df_cont[\"subj\"] + \"|\" + df_cont[\"obj\"] + \"|\" + df_cont[\"verb\"]\n",
    "    df_cont.insert(1, \"concept_id\", concept_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6994fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote stimuli_with_continuations.csv and stimuli_with_continuations.jsonl\n"
     ]
    }
   ],
   "source": [
    "df_cont.to_csv(os.path.join(STIMULI_DIR, \"stimuli_with_continuations.csv\"), index=False)\n",
    "\n",
    "with open(os.path.join(STIMULI_DIR, \"stimuli_with_continuations.jsonl\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in df_cont.to_dict(orient=\"records\"):\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Wrote stimuli_with_continuations.csv and stimuli_with_continuations.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
