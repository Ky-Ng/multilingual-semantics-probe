{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6cf6342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "# ----------------------------\n",
    "# Core tables (MEAN-based)\n",
    "# ----------------------------\n",
    "def preference_counts(\n",
    "    df: pd.DataFrame,\n",
    "    pref_col: str = \"preference_mean\",\n",
    "    by: Tuple[str, ...] = (\"model\", \"language\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Count inverse vs surface using pref_col (default: preference_mean)\n",
    "    Returns wide table: by..., inverse, surface, total, p_inverse\n",
    "    \"\"\"\n",
    "    missing = [c for c in (*by, pref_col) if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns for preference_counts: {missing}\")\n",
    "\n",
    "    counts_long = (\n",
    "        df.groupby(list(by) + [pref_col], dropna=False)\n",
    "          .size()\n",
    "          .rename(\"count\")\n",
    "          .reset_index()\n",
    "          .rename(columns={pref_col: \"preference\"})\n",
    "    )\n",
    "\n",
    "    wide = (\n",
    "        counts_long.pivot_table(\n",
    "            index=list(by),\n",
    "            columns=\"preference\",\n",
    "            values=\"count\",\n",
    "            aggfunc=\"sum\",\n",
    "            fill_value=0,\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    for c in [\"inverse\", \"surface\"]:\n",
    "        if c not in wide.columns:\n",
    "            wide[c] = 0\n",
    "\n",
    "    wide[\"total\"] = wide[\"inverse\"] + wide[\"surface\"]\n",
    "    wide[\"p_inverse\"] = wide[\"inverse\"] / wide[\"total\"].replace(0, pd.NA)\n",
    "\n",
    "    return wide[list(by) + [\"inverse\", \"surface\", \"total\", \"p_inverse\"]]\n",
    "\n",
    "\n",
    "def delta_summary(\n",
    "    df: pd.DataFrame,\n",
    "    by: Tuple[str, ...] = (\"model\", \"language\"),\n",
    "    cols: Tuple[str, ...] = (\"delta_mean\", \"ratio_mean\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Continuous summaries (count/mean/median/std) for mean-based columns\n",
    "    (default: delta_mean, ratio_mean).\n",
    "    \"\"\"\n",
    "    missing = [c for c in by if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns for delta_summary groupby: {missing}\")\n",
    "\n",
    "    cols_present = [c for c in cols if c in df.columns]\n",
    "    if not cols_present:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    out = (\n",
    "        df.groupby(list(by), dropna=False)[cols_present]\n",
    "          .agg([\"count\", \"mean\", \"median\", \"std\"])\n",
    "    )\n",
    "    out.columns = [\"__\".join(map(str, c)).strip() for c in out.columns.to_flat_index()]\n",
    "    return out.reset_index()\n",
    "\n",
    "\n",
    "def paired_preferences(\n",
    "    df: pd.DataFrame,\n",
    "    lang_a: str = \"en\",\n",
    "    lang_b: str = \"zh\",\n",
    "    value_col: str = \"preference_mean\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pair lang_a vs lang_b by (model, pair_id), using value_col (default: preference_mean).\n",
    "\n",
    "    Returns columns:\n",
    "      model, pair_id, <lang_a>, <lang_b>, agree, pattern\n",
    "    \"\"\"\n",
    "    needed = [\"model\", \"language\", \"pair_id\", value_col]\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns for paired_preferences: {missing}\")\n",
    "\n",
    "    sub = df[df[\"language\"].isin([lang_a, lang_b])][\n",
    "        [\"model\", \"language\", \"pair_id\", value_col]\n",
    "    ].copy()\n",
    "\n",
    "    pivot = (\n",
    "        sub.pivot_table(\n",
    "            index=[\"model\", \"pair_id\"],\n",
    "            columns=\"language\",\n",
    "            values=value_col,\n",
    "            aggfunc=\"first\",\n",
    "        )\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    if lang_a not in pivot.columns or lang_b not in pivot.columns:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    pivot[\"agree\"] = pivot[lang_a] == pivot[lang_b]\n",
    "    pivot[\"pattern\"] = (\n",
    "        pivot[lang_a].astype(str) + f\"_{lang_a.upper()}__\" +\n",
    "        pivot[lang_b].astype(str) + f\"_{lang_b.upper()}\"\n",
    "    )\n",
    "    return pivot\n",
    "\n",
    "\n",
    "def pair_agreement_by_model(pairs: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Agreement rate per model from paired_preferences output.\"\"\"\n",
    "    if pairs.empty:\n",
    "        return pairs\n",
    "    if \"model\" not in pairs.columns or \"agree\" not in pairs.columns:\n",
    "        raise ValueError(\"pairs must have columns: model, agree\")\n",
    "    return (\n",
    "        pairs.groupby(\"model\")[\"agree\"]\n",
    "             .mean()\n",
    "             .rename(\"agreement_rate\")\n",
    "             .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "def pair_pattern_counts(pairs: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Pattern counts per model from paired_preferences output.\"\"\"\n",
    "    if pairs.empty:\n",
    "        return pairs\n",
    "    if \"model\" not in pairs.columns or \"pattern\" not in pairs.columns:\n",
    "        raise ValueError(\"pairs must have columns: model, pattern\")\n",
    "    return (\n",
    "        pairs.groupby([\"model\", \"pattern\"])\n",
    "             .size()\n",
    "             .rename(\"count\")\n",
    "             .reset_index()\n",
    "             .sort_values([\"model\", \"count\"], ascending=[True, False])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c840cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List\n",
    "import pandas as pd\n",
    "\n",
    "def read_jsonl(path: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"Read JSONL file (one JSON object per line) into a DataFrame.\"\"\"\n",
    "    path = Path(path)\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"Bad JSON at {path}:{i}\") from e\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Normalize common string cols\n",
    "    for col in [\"model\", \"language\", \"pair_id\", \"stimulus_id\", \"template_id\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "\n",
    "    # Normalize preference labels (mean-based + sum-based if present)\n",
    "    for col in [\"preference_mean\", \"preference_sum\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.lower()\n",
    "\n",
    "    # Normalize numeric cols (mean-based preferred, but keep both if present)\n",
    "    numeric_cols = [\n",
    "        \"delta_mean\", \"ratio_mean\",\n",
    "        \"delta_sum\", \"ratio_sum\",\n",
    "        \"cont_log_probs_sum_inverse\", \"cont_log_probs_sum_surface\",\n",
    "        \"cont_log_probs_mean_inverse\", \"cont_log_probs_mean_surface\",\n",
    "        \"n_cont_tokens_inverse\", \"n_cont_tokens_surface\",\n",
    "    ]\n",
    "    for c in numeric_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_jsonl_many(paths: Iterable[str | Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read multiple JSONL files and concatenate.\n",
    "    Adds a `_source_file` column with the basename of each input file.\n",
    "    \"\"\"\n",
    "    dfs: List[pd.DataFrame] = []\n",
    "    for p in paths:\n",
    "        p = Path(p)\n",
    "        d = read_jsonl(p)\n",
    "        if not d.empty:\n",
    "            d = d.copy()\n",
    "            d[\"_source_file\"] = p.name\n",
    "            dfs.append(d)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ef48d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Pretty display helpers (Markdown)\n",
    "# ----------------------------\n",
    "def _fmt_percent(x: Any, digits: int = 1) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return f\"{float(x) * 100:.{digits}f}%\"\n",
    "\n",
    "def _fmt_float(x: Any, digits: int = 3) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return f\"{float(x):.{digits}f}\"\n",
    "\n",
    "def _fmt_int(x: Any) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return f\"{int(x):,d}\"\n",
    "\n",
    "def to_markdown_table(\n",
    "    df: pd.DataFrame,\n",
    "    index: bool = False,\n",
    "    tablefmt: str = \"github\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Return a text-based markdown table string.\n",
    "    Requires either 'tabulate' installed or pandas>=1.0 that bundles it.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return \"_(empty table)_\"\n",
    "    return df.to_markdown(index=index, tablefmt=tablefmt)\n",
    "\n",
    "def pretty_counts_markdown(\n",
    "    t: pd.DataFrame,\n",
    "    pct_col: str = \"p_inverse\",\n",
    "    pct_digits: int = 1,\n",
    "    index: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Markdown version of pretty_counts_table:\n",
    "    - formats p_inverse as percent\n",
    "    - formats inverse/surface/total as ints with commas\n",
    "    \"\"\"\n",
    "    if t.empty:\n",
    "        return \"_(empty table)_\"\n",
    "\n",
    "    df = t.copy()\n",
    "\n",
    "    # ints\n",
    "    for c in [\"inverse\", \"surface\", \"total\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].map(_fmt_int)\n",
    "\n",
    "    # percent\n",
    "    if pct_col in df.columns:\n",
    "        df[pct_col] = df[pct_col].map(lambda x: _fmt_percent(x, digits=pct_digits))\n",
    "\n",
    "    return to_markdown_table(df, index=index)\n",
    "\n",
    "def pretty_delta_markdown(\n",
    "    t: pd.DataFrame,\n",
    "    float_digits: int = 3,\n",
    "    index: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Markdown version of pretty_delta_table:\n",
    "    - formats __count columns as ints\n",
    "    - formats other numeric columns as floats\n",
    "    \"\"\"\n",
    "    if t.empty:\n",
    "        return \"_(empty table)_\"\n",
    "\n",
    "    df = t.copy()\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            if str(c).endswith(\"__count\"):\n",
    "                df[c] = df[c].map(_fmt_int)\n",
    "            else:\n",
    "                df[c] = df[c].map(lambda x: _fmt_float(x, digits=float_digits))\n",
    "\n",
    "    return to_markdown_table(df, index=index)\n",
    "\n",
    "def pretty_pair_agreement_markdown(\n",
    "    t: pd.DataFrame,\n",
    "    rate_col: str = \"agreement_rate\",\n",
    "    pct_digits: int = 1,\n",
    "    index: bool = False,\n",
    ") -> str:\n",
    "    if t.empty:\n",
    "        return \"_(empty table)_\"\n",
    "    df = t.copy()\n",
    "    if rate_col in df.columns:\n",
    "        df[rate_col] = df[rate_col].map(lambda x: _fmt_percent(x, digits=pct_digits))\n",
    "    return to_markdown_table(df, index=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3163d431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model                            | language   |   inverse |   surface |   total | p_inverse   |\n",
      "|----------------------------------|------------|-----------|-----------|---------|-------------|\n",
      "| uer_gpt2-chinese-cluecorpussmall | en         |        87 |        13 |     100 | 87.0%       |\n",
      "| uer_gpt2-chinese-cluecorpussmall | zh         |         0 |       100 |     100 | 0.0%        |\n",
      "\n",
      "| model                            | language   |   delta_mean__count |   delta_mean__mean |   delta_mean__median |   delta_mean__std |   ratio_mean__count |   ratio_mean__mean |   ratio_mean__median |   ratio_mean__std |\n",
      "|----------------------------------|------------|---------------------|--------------------|----------------------|-------------------|---------------------|--------------------|----------------------|-------------------|\n",
      "| uer_gpt2-chinese-cluecorpussmall | en         |                 100 |              0.31  |                0.251 |             0.275 |                 100 |              1.415 |                1.285 |             0.391 |\n",
      "| uer_gpt2-chinese-cluecorpussmall | zh         |                 100 |             -0.662 |               -0.646 |             0.178 |                 100 |              0.524 |                0.524 |             0.091 |\n",
      "\n",
      "| model                            | agreement_rate   |\n",
      "|----------------------------------|------------------|\n",
      "| uer_gpt2-chinese-cluecorpussmall | 13.0%            |\n",
      "\n",
      "| model                            | pattern                |   count |\n",
      "|----------------------------------|------------------------|---------|\n",
      "| uer_gpt2-chinese-cluecorpussmall | inverse_EN__surface_ZH |      87 |\n",
      "| uer_gpt2-chinese-cluecorpussmall | surface_EN__surface_ZH |      13 |\n"
     ]
    }
   ],
   "source": [
    "path = \"results/scored_wide_ue_uer_gpt2-chinese-cluecorpussmall.jsonl\"\n",
    "df = read_jsonl_many([path])\n",
    "\n",
    "counts = preference_counts(df)                 # DataFrame\n",
    "delta  = delta_summary(df)                     # DataFrame\n",
    "pairs  = paired_preferences(df, \"en\", \"zh\")     # DataFrame\n",
    "agree  = pair_agreement_by_model(pairs)        # DataFrame\n",
    "patts  = pair_pattern_counts(pairs)            # DataFrame\n",
    "\n",
    "print(pretty_counts_markdown(counts))\n",
    "print()\n",
    "\n",
    "print(pretty_delta_markdown(delta))\n",
    "print()\n",
    "\n",
    "print(pretty_pair_agreement_markdown(agree))\n",
    "print()\n",
    "\n",
    "print(to_markdown_table(patts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "51dd30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def wilcoxon_scope_test(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    delta_col: str = \"delta_mean\",\n",
    "    alternative: str = \"greater\",\n",
    "    drop_zeros: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run a Wilcoxon signed-rank test on per-stimulus log-prob differences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain `delta_col`.\n",
    "    delta_col : str\n",
    "        Column holding paired differences (inverse - surface).\n",
    "    alternative : {\"greater\", \"less\", \"two-sided\"}\n",
    "        Directional hypothesis.\n",
    "    drop_zeros : bool\n",
    "        Whether to drop exact-zero deltas (Wilcoxon requirement).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with test statistic, p-value, n, median, mean\n",
    "    \"\"\"\n",
    "    x = df[delta_col].dropna().to_numpy()\n",
    "\n",
    "    if drop_zeros:\n",
    "        x = x[x != 0.0]\n",
    "\n",
    "    if len(x) < 10:\n",
    "        raise ValueError(\"Too few non-zero samples for Wilcoxon test\")\n",
    "\n",
    "    stat, p = wilcoxon(x, alternative=alternative)\n",
    "\n",
    "    return {\n",
    "        \"n\": len(x),\n",
    "        \"statistic\": stat,\n",
    "        \"p_value\": p,\n",
    "        \"mean_delta\": float(np.mean(x)),\n",
    "        \"median_delta\": float(np.median(x)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "56c551bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 100,\n",
       " 'statistic': 4816.0,\n",
       " 'p_value': 1.6739642567252732e-15,\n",
       " 'mean_delta': 0.30960287570600004,\n",
       " 'median_delta': 0.2506902218}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n': 100,\n",
       " 'statistic': 0.0,\n",
       " 'p_value': 1.948279922547955e-18,\n",
       " 'mean_delta': -0.661983454224,\n",
       " 'median_delta': -0.6459811926000001}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_en = wilcoxon_scope_test(\n",
    "    df[df[\"language\"] == \"en\"],\n",
    "    delta_col=\"delta_mean\",\n",
    "    alternative=\"greater\",  # inverse preferred\n",
    ")\n",
    "\n",
    "results_zh = wilcoxon_scope_test(\n",
    "    df[df[\"language\"] == \"zh\"],\n",
    "    delta_col=\"delta_mean\",\n",
    "    alternative=\"less\",     # surface preferred\n",
    ")\n",
    "display(results_en)\n",
    "display(results_zh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
