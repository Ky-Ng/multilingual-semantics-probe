{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ea2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf6342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "# ----------------------------\n",
    "# Core tables (MEAN-based)\n",
    "# ----------------------------\n",
    "def preference_counts(\n",
    "    df: pd.DataFrame,\n",
    "    pref_col: str = \"preference_mean\",\n",
    "    by: Tuple[str, ...] = (\"model\", \"language\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Count inverse vs surface using pref_col (default: preference_mean)\n",
    "    Returns wide table: by..., inverse, surface, total, p_inverse\n",
    "    \"\"\"\n",
    "    missing = [c for c in (*by, pref_col) if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns for preference_counts: {missing}\")\n",
    "\n",
    "    counts_long = (\n",
    "        df.groupby(list(by) + [pref_col], dropna=False)\n",
    "          .size()\n",
    "          .rename(\"count\")\n",
    "          .reset_index()\n",
    "          .rename(columns={pref_col: \"preference\"})\n",
    "    )\n",
    "\n",
    "    wide = (\n",
    "        counts_long.pivot_table(\n",
    "            index=list(by),\n",
    "            columns=\"preference\",\n",
    "            values=\"count\",\n",
    "            aggfunc=\"sum\",\n",
    "            fill_value=0,\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    for c in [\"inverse\", \"surface\"]:\n",
    "        if c not in wide.columns:\n",
    "            wide[c] = 0\n",
    "\n",
    "    wide[\"total\"] = wide[\"inverse\"] + wide[\"surface\"]\n",
    "    wide[\"p_inverse\"] = wide[\"inverse\"] / wide[\"total\"].replace(0, pd.NA)\n",
    "\n",
    "    return wide[list(by) + [\"inverse\", \"surface\", \"total\", \"p_inverse\"]]\n",
    "\n",
    "\n",
    "def delta_summary(\n",
    "    df: pd.DataFrame,\n",
    "    by: Tuple[str, ...] = (\"model\", \"language\"),\n",
    "    cols: Tuple[str, ...] = (\"delta_mean\", \"ratio_mean\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Continuous summaries (count/mean/median/std) for mean-based columns\n",
    "    (default: delta_mean, ratio_mean).\n",
    "    \"\"\"\n",
    "    missing = [c for c in by if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns for delta_summary groupby: {missing}\")\n",
    "\n",
    "    cols_present = [c for c in cols if c in df.columns]\n",
    "    if not cols_present:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    out = (\n",
    "        df.groupby(list(by), dropna=False)[cols_present]\n",
    "          .agg([\"count\", \"mean\", \"median\", \"std\"])\n",
    "    )\n",
    "    out.columns = [\"__\".join(map(str, c)).strip() for c in out.columns.to_flat_index()]\n",
    "    return out.reset_index()\n",
    "\n",
    "\n",
    "def paired_preferences(\n",
    "    df: pd.DataFrame,\n",
    "    lang_a: str = \"en\",\n",
    "    lang_b: str = \"zh\",\n",
    "    value_col: str = \"preference_mean\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pair lang_a vs lang_b by (model, pair_id), using value_col (default: preference_mean).\n",
    "\n",
    "    Returns columns:\n",
    "      model, pair_id, <lang_a>, <lang_b>, agree, pattern\n",
    "    \"\"\"\n",
    "    needed = [\"model\", \"language\", \"pair_id\", value_col]\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns for paired_preferences: {missing}\")\n",
    "\n",
    "    sub = df[df[\"language\"].isin([lang_a, lang_b])][\n",
    "        [\"model\", \"language\", \"pair_id\", value_col]\n",
    "    ].copy()\n",
    "\n",
    "    pivot = (\n",
    "        sub.pivot_table(\n",
    "            index=[\"model\", \"pair_id\"],\n",
    "            columns=\"language\",\n",
    "            values=value_col,\n",
    "            aggfunc=\"first\",\n",
    "        )\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    if lang_a not in pivot.columns or lang_b not in pivot.columns:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    pivot[\"agree\"] = pivot[lang_a] == pivot[lang_b]\n",
    "    pivot[\"pattern\"] = (\n",
    "        pivot[lang_a].astype(str) + f\"_{lang_a.upper()}__\" +\n",
    "        pivot[lang_b].astype(str) + f\"_{lang_b.upper()}\"\n",
    "    )\n",
    "    return pivot\n",
    "\n",
    "\n",
    "def pair_agreement_by_model(pairs: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Agreement rate per model from paired_preferences output.\"\"\"\n",
    "    if pairs.empty:\n",
    "        return pairs\n",
    "    if \"model\" not in pairs.columns or \"agree\" not in pairs.columns:\n",
    "        raise ValueError(\"pairs must have columns: model, agree\")\n",
    "    return (\n",
    "        pairs.groupby(\"model\")[\"agree\"]\n",
    "             .mean()\n",
    "             .rename(\"agreement_rate\")\n",
    "             .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "def pair_pattern_counts(pairs: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Pattern counts per model from paired_preferences output.\"\"\"\n",
    "    if pairs.empty:\n",
    "        return pairs\n",
    "    if \"model\" not in pairs.columns or \"pattern\" not in pairs.columns:\n",
    "        raise ValueError(\"pairs must have columns: model, pattern\")\n",
    "    return (\n",
    "        pairs.groupby([\"model\", \"pattern\"])\n",
    "             .size()\n",
    "             .rename(\"count\")\n",
    "             .reset_index()\n",
    "             .sort_values([\"model\", \"count\"], ascending=[True, False])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c840cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List\n",
    "import pandas as pd\n",
    "\n",
    "def read_jsonl(path: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"Read JSONL file (one JSON object per line) into a DataFrame.\"\"\"\n",
    "    path = Path(path)\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"Bad JSON at {path}:{i}\") from e\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Normalize common string cols\n",
    "    for col in [\"model\", \"language\", \"pair_id\", \"stimulus_id\", \"template_id\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "\n",
    "    # Normalize preference labels (mean-based + sum-based if present)\n",
    "    for col in [\"preference_mean\", \"preference_sum\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.lower()\n",
    "\n",
    "    # Normalize numeric cols (mean-based preferred, but keep both if present)\n",
    "    numeric_cols = [\n",
    "        \"delta_mean\", \"ratio_mean\",\n",
    "        \"delta_sum\", \"ratio_sum\",\n",
    "        \"cont_log_probs_sum_inverse\", \"cont_log_probs_sum_surface\",\n",
    "        \"cont_log_probs_mean_inverse\", \"cont_log_probs_mean_surface\",\n",
    "        \"n_cont_tokens_inverse\", \"n_cont_tokens_surface\",\n",
    "    ]\n",
    "    for c in numeric_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_jsonl_many(paths: Iterable[str | Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read multiple JSONL files and concatenate.\n",
    "    Adds a `_source_file` column with the basename of each input file.\n",
    "    \"\"\"\n",
    "    dfs: List[pd.DataFrame] = []\n",
    "    for p in paths:\n",
    "        p = Path(p)\n",
    "        d = read_jsonl(p)\n",
    "        if not d.empty:\n",
    "            d = d.copy()\n",
    "            d[\"_source_file\"] = p.name\n",
    "            dfs.append(d)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef48d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Pretty display helpers (Markdown)\n",
    "# ----------------------------\n",
    "def _fmt_percent(x: Any, digits: int = 1) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return f\"{float(x) * 100:.{digits}f}%\"\n",
    "\n",
    "def _fmt_float(x: Any, digits: int = 3) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return f\"{float(x):.{digits}f}\"\n",
    "\n",
    "def _fmt_int(x: Any) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return f\"{int(x):,d}\"\n",
    "\n",
    "def to_markdown_table(\n",
    "    df: pd.DataFrame,\n",
    "    index: bool = False,\n",
    "    tablefmt: str = \"github\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Return a text-based markdown table string.\n",
    "    Requires either 'tabulate' installed or pandas>=1.0 that bundles it.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return \"_(empty table)_\"\n",
    "    return df.to_markdown(index=index, tablefmt=tablefmt)\n",
    "\n",
    "def pretty_counts_markdown(\n",
    "    t: pd.DataFrame,\n",
    "    pct_col: str = \"p_inverse\",\n",
    "    pct_digits: int = 1,\n",
    "    index: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Markdown version of pretty_counts_table:\n",
    "    - formats p_inverse as percent\n",
    "    - formats inverse/surface/total as ints with commas\n",
    "    \"\"\"\n",
    "    if t.empty:\n",
    "        return \"_(empty table)_\"\n",
    "\n",
    "    df = t.copy()\n",
    "\n",
    "    # ints\n",
    "    for c in [\"inverse\", \"surface\", \"total\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].map(_fmt_int)\n",
    "\n",
    "    # percent\n",
    "    if pct_col in df.columns:\n",
    "        df[pct_col] = df[pct_col].map(lambda x: _fmt_percent(x, digits=pct_digits))\n",
    "\n",
    "    return to_markdown_table(df, index=index)\n",
    "\n",
    "def pretty_delta_markdown(\n",
    "    t: pd.DataFrame,\n",
    "    float_digits: int = 3,\n",
    "    index: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Markdown version of pretty_delta_table:\n",
    "    - formats __count columns as ints\n",
    "    - formats other numeric columns as floats\n",
    "    \"\"\"\n",
    "    if t.empty:\n",
    "        return \"_(empty table)_\"\n",
    "\n",
    "    df = t.copy()\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            if str(c).endswith(\"__count\"):\n",
    "                df[c] = df[c].map(_fmt_int)\n",
    "            else:\n",
    "                df[c] = df[c].map(lambda x: _fmt_float(x, digits=float_digits))\n",
    "\n",
    "    return to_markdown_table(df, index=index)\n",
    "\n",
    "def pretty_pair_agreement_markdown(\n",
    "    t: pd.DataFrame,\n",
    "    rate_col: str = \"agreement_rate\",\n",
    "    pct_digits: int = 1,\n",
    "    index: bool = False,\n",
    ") -> str:\n",
    "    if t.empty:\n",
    "        return \"_(empty table)_\"\n",
    "    df = t.copy()\n",
    "    if rate_col in df.columns:\n",
    "        df[rate_col] = df[rate_col].map(lambda x: _fmt_percent(x, digits=pct_digits))\n",
    "    return to_markdown_table(df, index=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3163d431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model                                   | language   |   inverse |   surface |   total | p_inverse   |\n",
      "|-----------------------------------------|------------|-----------|-----------|---------|-------------|\n",
      "| uer_gpt2-distil-chinese-cluecorpussmall | en         |        64 |         0 |      64 | 100.0%      |\n",
      "| uer_gpt2-distil-chinese-cluecorpussmall | zh         |         0 |        64 |      64 | 0.0%        |\n",
      "\n",
      "| model                                   | language   |   delta_mean__count |   delta_mean__mean |   delta_mean__median |   delta_mean__std |   ratio_mean__count |   ratio_mean__mean |   ratio_mean__median |   ratio_mean__std |\n",
      "|-----------------------------------------|------------|---------------------|--------------------|----------------------|-------------------|---------------------|--------------------|----------------------|-------------------|\n",
      "| uer_gpt2-distil-chinese-cluecorpussmall | en         |                  64 |              1.15  |                1.047 |             0.326 |                  64 |              3.34  |                2.855 |             1.201 |\n",
      "| uer_gpt2-distil-chinese-cluecorpussmall | zh         |                  64 |             -0.858 |               -0.869 |             0.212 |                  64 |              0.433 |                0.419 |             0.091 |\n",
      "\n",
      "| model                                   | agreement_rate   |\n",
      "|-----------------------------------------|------------------|\n",
      "| uer_gpt2-distil-chinese-cluecorpussmall | 0.0%             |\n",
      "\n",
      "| model                                   | pattern                |   count |\n",
      "|-----------------------------------------|------------------------|---------|\n",
      "| uer_gpt2-distil-chinese-cluecorpussmall | inverse_EN__surface_ZH |      64 |\n"
     ]
    }
   ],
   "source": [
    "df = read_jsonl_many([\"results/scored_wide_uer_gpt2-distil-chinese-cluecorpussmall.jsonl\"])\n",
    "\n",
    "counts = preference_counts(df)                 # DataFrame\n",
    "delta  = delta_summary(df)                     # DataFrame\n",
    "pairs  = paired_preferences(df, \"en\", \"zh\")     # DataFrame\n",
    "agree  = pair_agreement_by_model(pairs)        # DataFrame\n",
    "patts  = pair_pattern_counts(pairs)            # DataFrame\n",
    "\n",
    "print(pretty_counts_markdown(counts))\n",
    "print()\n",
    "\n",
    "print(pretty_delta_markdown(delta))\n",
    "print()\n",
    "\n",
    "print(pretty_pair_agreement_markdown(agree))\n",
    "print()\n",
    "\n",
    "print(to_markdown_table(patts))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
